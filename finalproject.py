# -*- coding: utf-8 -*-
"""FinalProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qsIz4rcvipbJgP6wPLU_AN1u1JeyNq8l

## Final Project
### Name: Behnam Sobhani Nadri
### Student ID: 801368949

https://www.kaggle.com/datasets/sampadab17/network-intrusion-detection

Code Example: https://www.kaggle.com/code/ahmedbasem/99-6-accuracy-network-intrusion-detection

## Questions

### Does different random state helps?
### Does it important to compare models or tuning the hyperparameters?
### Does it matter what preprocessing to use?
### Does it matter to do Regularization? or PCA?

### compare against models Changing the parameters to have the best model

## All libraries that we use in the lab is defined here
"""

import warnings
import pandas as pd
import numpy as np
import seaborn as sb
from google.colab import drive
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap

from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split

from sklearn import svm
from sklearn import tree
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder
from sklearn.naive_bayes import GaussianNB
from sklearn.naive_bayes import BernoulliNB
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier


from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import confusion_matrix
from sklearn import metrics

drive.mount('/content/drive')

file_path='/content/drive/My Drive/Courses/Intro to ML/Project/network_data.csv'
df_network = pd.read_csv(file_path)

file_path='/content/drive/My Drive/Courses/Intro to ML/Project/Test_data.csv'
df_network_test = pd.read_csv(file_path)


df_network_1 = pd.DataFrame((df_network.iloc[:,1] == "tcp").replace(True,1).replace(False,0)).rename(columns={'protocol_type':'tcp_protocol'})
df_network = pd.concat([df_network, df_network_1], axis = 1)
df_network_2 = pd.DataFrame((df_network.iloc[:,1] == "udp").replace(True,1).replace(False,0)).rename(columns={'protocol_type':'udp_protocol'})
df_network = pd.concat([df_network, df_network_2], axis = 1)
df_network_3 = pd.DataFrame((df_network.iloc[:,1] == "icmp").replace(True,1).replace(False,0)).rename(columns={'protocol_type':'icmp_protocol'})
df_network = pd.concat([df_network, df_network_3], axis = 1)
df_network_4 = pd.DataFrame((df_network.iloc[:,41] == "anomaly").replace(True,1).replace(False,0)).rename(columns={'class':'class_t'})
df_network = pd.concat([df_network, df_network_4], axis = 1)
df_network = df_network.drop(['service','flag','protocol_type','class'],axis=1) # Not sure to keep the protocol or not
# Choose the features based on
df_network.head(20)

df_network.describe()

"""## Feature Correlation"""

X = df_network.iloc[:,1:41].values
Y = df_network.iloc[:,41].values

"""### Logistic Regression Classifier"""

# K=40
# accur = np.zeros((K,2))
# prec = np.zeros((K,2))
# rec = np.zeros((K,2))
# f1 = np.zeros((K,2))

# for i in range(K):
#     # X = df_cancer.iloc[:,1:31].values
#     # Y = df_cancer.iloc[:,31].values
#     # print(i)
#     decomposer = PCA(n_components=i+1)
#     X_r = decomposer.fit(X).transform(X)
#     X_train_r, X_test_r, Y_train, Y_test = train_test_split(X_r,Y, test_size=0.25, random_state = 2)
#     sc_X = StandardScaler()
#     X_train_r = sc_X.fit_transform(X_train_r)
#     X_test_r = sc_X.transform(X_test_r)
#     # classifier = svm.SVC()
#     classifier = LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000)
#     classifier.fit(X_train_r, Y_train)
#     Y_pred = classifier.predict(X_test_r)
#     accur [ i, 0]=i+1
#     accur [i,1] = metrics.accuracy_score(Y_test, Y_pred)
#     prec [ i, 0]=i+1
#     prec [i,1] = metrics.precision_score(Y_test, Y_pred)
#     rec [ i, 0]=i+1
#     rec [i,1] = metrics.recall_score(Y_test, Y_pred)
#     f1 [ i, 0]=i+1
#     f1 [i,1] = metrics.f1_score(Y_test, Y_pred)

# maximum_accur = max(accur[:,1])
# print("Maximum Accuracy is:", maximum_accur)
# print("Maximum Accuracy is at K:", accur[accur[:,1] == maximum_accur][0,0])

plt.plot(accur[:,0],accur[:,1])
plt.rcParams["figure.figsize"] = (10,6)
plt.grid(1)
plt.xlabel('Number of Components (K)')
plt.ylabel('Accuracy')
plt.title('Accuracy vs Number of Components (K)')
plt.legend()

plt.plot(prec[:,0],prec[:,1])
plt.rcParams["figure.figsize"] = (10,6)
plt.grid(1)
plt.xlabel('Number of Components (K)')
plt.ylabel('Precision')
plt.title('Precision vs Number of Components (K)')
plt.legend()

plt.plot(rec[:,0],rec[:,1])
plt.rcParams["figure.figsize"] = (10,6)
plt.grid(1)
plt.xlabel('Number of Number of Components (K)')
plt.ylabel('Recall')
plt.title('Recall vs Number of Components (K)')
plt.legend()

plt.plot(f1[:,0],f1[:,1])
plt.rcParams["figure.figsize"] = (10,6)
plt.grid(1)
plt.xlabel('Number of Number of Components (K)')
plt.ylabel('F1-score')
plt.title('F1-score vs Number of Number of Components (K)')
plt.legend()

K=18

decomposer = PCA(n_components=K)
X_r = decomposer.fit(X).transform(X)
X_train_r, X_test_r, Y_train, Y_test = train_test_split(X_r,Y, test_size=0.25, random_state = 2)
sc_X = StandardScaler()
X_train_r = sc_X.fit_transform(X_train_r)
X_test_r = sc_X.transform(X_test_r)
classifier = LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000)
classifier.fit(X_train_r, Y_train)
Y_pred = classifier.predict(X_test_r)

print("Accuracy:", metrics.accuracy_score(Y_test, Y_pred))
print("Precision:", metrics.precision_score(Y_test,Y_pred))
print("Recall:", metrics.recall_score(Y_test,Y_pred))
print("F1-score:", metrics.f1_score(Y_test,Y_pred))

titles_options = [
        ("Confusion matrix, without normalization", None),
        ("Normalized confusion matrix", "true"),
    ]
for title, normalize in titles_options:
    disp = ConfusionMatrixDisplay.from_estimator(
    classifier,
    X_test_r,
    Y_test,
    display_labels=classifier.classes_,
    cmap=plt.cm.Blues,
    normalize=normalize
  )
    disp.ax_.set_title(title)
    print(title)
    print(disp.confusion_matrix)

    # plt.savefig(f'fig/conf_matrix_{classifier}')

titles_options = [
        ("Confusion matrix, without normalization", None),
        ("Normalized confusion matrix", "true"),
    ]
for title, normalize in titles_options:
    disp = ConfusionMatrixDisplay.from_estimator(
    classifier,
    X_test_r,
    Y_test,
    display_labels=classifier.classes_,
    cmap=plt.cm.Blues,
    normalize=normalize
  )
    disp.ax_.set_title(title)
    print(title)
    print(disp.confusion_matrix)

X_train_r, X_test_r, Y_train, Y_test = train_test_split(X,Y, test_size=0.25, random_state = 2)
sc_X = StandardScaler()
X_train_r = sc_X.fit_transform(X_train_r)
X_test_r = sc_X.transform(X_test_r)
classifier = LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000)
classifier.fit(X_train_r, Y_train)
Y_pred = classifier.predict(X_test_r)

print("Accuracy:", metrics.accuracy_score(Y_test, Y_pred))
print("Precision:", metrics.precision_score(Y_test,Y_pred))
print("Recall:", metrics.recall_score(Y_test,Y_pred))
print("F1-score:", metrics.f1_score(Y_test,Y_pred))

"""### Support Vector Machine (SVM) Classifier"""

# K=40
# # kern='sigmoid'
# # kern='poly'
# kern='linear'
# accur = np.zeros((K,2))
# prec = np.zeros((K,2))
# rec = np.zeros((K,2))
# f1 = np.zeros((K,2))

# for i in range(K):

#     decomposer = PCA(n_components=i+1)
#     X_r = decomposer.fit(X).transform(X)
#     X_train_r, X_test_r, Y_train, Y_test = train_test_split(X_r,Y, test_size=0.25, random_state = 2)
#     sc_X = StandardScaler()
#     X_train_r = sc_X.fit_transform(X_train_r)
#     X_test_r = sc_X.transform(X_test_r)
#     classifier = svm.SVC(kernel=kern)
#     # classifier = LogisticRegression(random_state=0, solver='lbfgs', max_iter=1000)
#     classifier.fit(X_train_r, Y_train)
#     Y_pred = classifier.predict(X_test_r)
#     accur [ i, 0]=i+1
#     accur [i,1] = metrics.accuracy_score(Y_test, Y_pred)
#     prec [ i, 0]=i+1
#     prec [i,1] = metrics.precision_score(Y_test, Y_pred)
#     rec [ i, 0]=i+1
#     rec [i,1] = metrics.recall_score(Y_test, Y_pred)
#     f1 [ i, 0]=i+1
#     f1 [i,1] = metrics.f1_score(Y_test, Y_pred)

# maximum_accur = max(accur[:,1])
# print("Maximum Accuracy is:", maximum_accur)
# print("Maximum Accuracy is at K:", accur[accur[:,1] == maximum_accur][0,0])

plt.plot(accur[:,0],accur[:,1])
plt.rcParams["figure.figsize"] = (10,6)
plt.grid(1)
plt.xlabel('Number of Components (K)')
plt.ylabel('Accuracy')
plt.title('Accuracy vs Number of Components (K) for SVM ')
plt.legend()

plt.plot(prec[:,0],prec[:,1])
plt.rcParams["figure.figsize"] = (10,6)
plt.grid(1)
plt.xlabel('Number of Components (K)')
plt.ylabel('Precision')
plt.title('Precision vs Number of Components (K) for SVM')
plt.legend()

plt.plot(rec[:,0],rec[:,1])
plt.rcParams["figure.figsize"] = (10,6)
plt.grid(1)
plt.xlabel('Number of Number of Components (K)')
plt.ylabel('Recall')
plt.title('Recall vs Number of Components (K) for SVM')
plt.legend()

plt.plot(f1[:,0],f1[:,1])
plt.rcParams["figure.figsize"] = (10,6)
plt.grid(1)
plt.xlabel('Number of Number of Components (K)')
plt.ylabel('F1-score')
plt.title('F1-score vs Number of Number of Components (K) for SVM')
plt.legend()

K=21
kern='sigmoid'
# kern='poly'
# kern='linear'
# kern='precomputed'

decomposer = PCA(n_components=K)
X_r = decomposer.fit(X).transform(X)
X_train_r, X_test_r, Y_train, Y_test = train_test_split(X_r,Y, test_size=0.25, random_state = 0)
sc_X = StandardScaler()
X_train_r = sc_X.fit_transform(X_train_r)
X_test_r = sc_X.transform(X_test_r)
classifier = svm.SVC(kernel=kern)
classifier.fit(X_train_r, Y_train)
Y_pred = classifier.predict(X_test_r)

print("Accuracy:", metrics.accuracy_score(Y_test, Y_pred))
print("Precision:", metrics.precision_score(Y_test,Y_pred))
print("Recall:", metrics.recall_score(Y_test,Y_pred))
print("F1-score:", metrics.f1_score(Y_test,Y_pred))

titles_options = [
        ("Confusion matrix, without normalization", None),
        ("Normalized confusion matrix", "true"),
    ]
for title, normalize in titles_options:
    disp = ConfusionMatrixDisplay.from_estimator(
    classifier,
    X_test_r,
    Y_test,
    display_labels=classifier.classes_,
    cmap=plt.cm.Blues,
    normalize=normalize
  )
    disp.ax_.set_title(title)
    print(title)
    print(disp.confusion_matrix)

"""### SVM without PCA"""

kern='sigmoid'
# kern='poly'
# kern='linear'

X_train_r, X_test_r, Y_train, Y_test = train_test_split(X,Y, test_size=0.25, random_state = 2)
sc_X = StandardScaler()
X_train_r = sc_X.fit_transform(X_train_r)
X_test_r = sc_X.transform(X_test_r)
classifier = svm.SVC(kernel=kern)
classifier.fit(X_train_r, Y_train)
Y_pred = classifier.predict(X_test_r)

print("Accuracy:", metrics.accuracy_score(Y_test, Y_pred))
print("Precision:", metrics.precision_score(Y_test,Y_pred))
print("Recall:", metrics.recall_score(Y_test,Y_pred))
print("F1-score:", metrics.f1_score(Y_test,Y_pred))

titles_options = [
        ("Confusion matrix, without normalization", None),
        ("Normalized confusion matrix", "true"),
    ]
for title, normalize in titles_options:
    disp = ConfusionMatrixDisplay.from_estimator(
    classifier,
    X_test_r,
    Y_test,
    display_labels=classifier.classes_,
    cmap=plt.cm.Blues,
    normalize=normalize
  )
    disp.ax_.set_title(title)
    print(title)
    print(disp.confusion_matrix)

"""### Naive Bayes (NB) Classifier"""

K=40

accur = np.zeros((K,2))
prec = np.zeros((K,2))
rec = np.zeros((K,2))
f1 = np.zeros((K,2))

for i in range(K):

    decomposer = PCA(n_components=i+1)
    X_r = decomposer.fit(X).transform(X)
    X_train_r, X_test_r, Y_train, Y_test = train_test_split(X_r,Y, test_size=0.25, random_state = 2)
    sc_X = StandardScaler()
    X_train_r = sc_X.fit_transform(X_train_r)
    X_test_r = sc_X.transform(X_test_r)
    classifier = GaussianNB()
    classifier.fit(X_train_r, Y_train)
    Y_pred = classifier.predict(X_test_r)
    accur [ i, 0]=i+1
    accur [i,1] = metrics.accuracy_score(Y_test, Y_pred)
    prec [ i, 0]=i+1
    prec [i,1] = metrics.precision_score(Y_test, Y_pred)
    rec [ i, 0]=i+1
    rec [i,1] = metrics.recall_score(Y_test, Y_pred)
    f1 [ i, 0]=i+1
    f1 [i,1] = metrics.f1_score(Y_test, Y_pred)

maximum_accur = max(accur[:,1])
print("Maximum Accuracy is:", maximum_accur)
print("Maximum Accuracy is at K:", accur[accur[:,1] == maximum_accur][0,0])

plt.plot(accur[:,0],accur[:,1])
plt.rcParams["figure.figsize"] = (10,6)
plt.grid(1)
plt.xlabel('Number of Components (K)')
plt.ylabel('Accuracy')
plt.title('Accuracy vs Number of Components (K) for Gaussian Naive Bayes ')
plt.legend()

plt.plot(prec[:,0],prec[:,1])
plt.rcParams["figure.figsize"] = (10,6)
plt.grid(1)
plt.xlabel('Number of Components (K)')
plt.ylabel('Precision')
plt.title('Precision vs Number of Components (K) for Gaussian Naive Bayes')
plt.legend()

plt.plot(rec[:,0],rec[:,1])
plt.rcParams["figure.figsize"] = (10,6)
plt.grid(1)
plt.xlabel('Number of Number of Components (K)')
plt.ylabel('Recall')
plt.title('Recall vs Number of Components (K) for Gaussian Naive Bayes')
plt.legend()

plt.plot(f1[:,0],f1[:,1])
plt.rcParams["figure.figsize"] = (10,6)
plt.grid(1)
plt.xlabel('Number of Number of Components (K)')
plt.ylabel('F1-score')
plt.title('F1-score vs Number of Number of Components (K) for Gaussian Naive Bayes')
plt.legend()

K=21

decomposer = PCA(n_components=K)
X_r = decomposer.fit(X).transform(X)
X_train_r, X_test_r, Y_train, Y_test = train_test_split(X_r,Y, test_size=0.25, random_state = 2)
sc_X = StandardScaler()
X_train_r = sc_X.fit_transform(X_train_r)
X_test_r = sc_X.transform(X_test_r)
classifier = GaussianNB()
classifier.fit(X_train_r, Y_train)
Y_pred = classifier.predict(X_test_r)

print("Accuracy:", metrics.accuracy_score(Y_test, Y_pred))
print("Precision:", metrics.precision_score(Y_test,Y_pred))
print("Recall:", metrics.recall_score(Y_test,Y_pred))
print("F1-score:", metrics.f1_score(Y_test,Y_pred))

titles_options = [
        ("Confusion matrix, without normalization", None),
        ("Normalized confusion matrix", "true"),
    ]
for title, normalize in titles_options:
    disp = ConfusionMatrixDisplay.from_estimator(
    classifier,
    X_test_r,
    Y_test,
    display_labels=classifier.classes_,
    cmap=plt.cm.Blues,
    normalize=normalize
  )
    disp.ax_.set_title(title)
    print(title)
    print(disp.confusion_matrix)

"""### Guassion NB Without PCA"""

X_train_r, X_test_r, Y_train, Y_test = train_test_split(X,Y, test_size=0.25, random_state = 2)
sc_X = StandardScaler()
X_train_r = sc_X.fit_transform(X_train_r)
X_test_r = sc_X.transform(X_test_r)
classifier = GaussianNB()
classifier.fit(X_train_r, Y_train)
Y_pred = classifier.predict(X_test_r)

print("Accuracy:", metrics.accuracy_score(Y_test, Y_pred))
print("Precision:", metrics.precision_score(Y_test,Y_pred))
print("Recall:", metrics.recall_score(Y_test,Y_pred))
print("F1-score:", metrics.f1_score(Y_test,Y_pred))

titles_options = [
        ("Confusion matrix, without normalization", None),
        ("Normalized confusion matrix", "true"),
    ]
for title, normalize in titles_options:
    disp = ConfusionMatrixDisplay.from_estimator(
    classifier,
    X_test_r,
    Y_test,
    display_labels=classifier.classes_,
    cmap=plt.cm.Blues,
    normalize=normalize
  )
    disp.ax_.set_title(title)
    print(title)
    print(disp.confusion_matrix)

# plt.plot(accur[:,0],accur[:,1])
# plt.rcParams["figure.figsize"] = (10,6)
# plt.grid(1)
# plt.xlabel('Number of Components (K)')
# plt.ylabel('Accuracy')
# plt.title('Accuracy vs Number of Components (K)')
# plt.legend()

# plt.plot(prec[:,0],prec[:,1])
# plt.rcParams["figure.figsize"] = (10,6)
# plt.grid(1)
# plt.xlabel('Number of Components (K)')
# plt.ylabel('Precision')
# plt.title('Precision vs Number of Components (K)')
# plt.legend()

# plt.plot(rec[:,0],rec[:,1])
# plt.rcParams["figure.figsize"] = (10,6)
# plt.grid(1)
# plt.xlabel('Number of Number of Components (K)')
# plt.ylabel('Recall')
# plt.title('Recall vs Number of Components (K)')
# plt.legend()

# plt.plot(f1[:,0],f1[:,1])
# plt.rcParams["figure.figsize"] = (10,6)
# plt.grid(1)
# plt.xlabel('Number of Number of Components (K)')
# plt.ylabel('F1-score')
# plt.title('F1-score vs Number of Number of Components (K)')
# plt.legend()